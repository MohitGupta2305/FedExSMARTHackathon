# -*- coding: utf-8 -*-
"""agent-1.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qCqp1xr7Nw-067yuzRvZq4vH8Au2x_DG
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta

# Set seed for reproducibility
np.random.seed(42)

# 1. CUSTOMER DIMENSION DATA (dim_customers)
customers = pd.DataFrame({
    'cust_id': [f'CUST_{i:03d}' for i in range(1, 11)],
    'customer_name': ['Global Corp', 'Tech Retail', 'HealthInc', 'AutoParts Co', 'BioPharma',
                     'EduGroup', 'FastFood Ltd', 'Energy Solutions', 'LogiTrans', 'SoftSystems'],
    'industry': ['Enterprise', 'Retail', 'Healthcare', 'Manufacturing', 'Healthcare',
                 'Education', 'Retail', 'Energy', 'Logistics', 'Enterprise'],
    'credit_limit': [500000, 50000, 200000, 150000, 300000, 20000, 40000, 450000, 100000, 250000]
})

# 2. FINANCIAL DATA (erp_invoices_raw)
# Simulating current overdue invoices
invoices = pd.DataFrame({
    'invoice_id': [f'INV_{i:03d}' for i in range(1, 11)],
    'cust_id': customers['cust_id'],
    'amount': [120000, 5000, 85000, 12000, 150000, 1500, 3000, 210000, 45000, 90000],
    'due_date': [(datetime.now() - timedelta(days=x)).strftime('%Y-%m-%d') for x in [15, 45, 10, 60, 5, 90, 20, 12, 35, 8]]
})

# 3. HISTORICAL PERFORMANCE (fact_payment_history)
# dbt_avg = Days Beyond Terms Average
history = pd.DataFrame({
    'cust_id': customers['cust_id'],
    'dbt_avg': [5, 40, 2, 55, 4, 85, 12, 3, 25, 6],
    'prev_ptp_hit_rate': [0.95, 0.40, 0.98, 0.20, 0.90, 0.10, 0.75, 0.99, 0.60, 0.92],
    'total_cases_last_12m': [1, 8, 0, 12, 2, 15, 4, 1, 6, 2]
})

# 4. SERVICENOW LOGS (servicenow_cases_raw)
# Sentiment score: 1.0 (Positive) to -1.0 (Hostile)
service_now = pd.DataFrame({
    'cust_id': customers['cust_id'],
    'last_case_sentiment': [0.2, -0.8, 0.5, -0.9, 0.1, -1.0, -0.2, 0.6, -0.5, 0.3],
    'open_disputes': [0, 1, 0, 2, 0, 1, 0, 0, 1, 0]
})

# Display first few rows of the main joined testing set
test_data = invoices.merge(customers, on='cust_id').merge(history, on='cust_id').merge(service_now, on='cust_id')
print(test_data[['cust_id', 'amount', 'due_date', 'dbt_avg', 'last_case_sentiment']])

# Save to CSV for testing your pipeline
# test_data.to_csv('agent_1_test_data.csv', index=False)

import pandas as pd
import numpy as np

# Initialize Faker for consistency, though not strictly needed for this task
# from faker import Faker
# fake = Faker()

# List to store records for the Customer_ratings DataFrame
customer_ratings_records = []

# Iterate through each customer in new_customers_df
for index, customer_row in new_customers_df.iterrows():
    cust_id = customer_row['cust_id']
    credit_limit = customer_row['credit_limit']

    # AVG_DEBT - random value < credit_limit of customer
    # Ensure AVG_DEBT is at least 0, and less than credit_limit
    avg_debt = np.random.randint(0, credit_limit) if credit_limit > 0 else 0

    # prev_ptp_hit_rate - value between 0-1, upto 2 decimals
    prev_ptp_hit_rate = round(np.random.uniform(0.0, 1.0), 2)

    # total cases in last 12months - random number between 1-10
    total_cases_last_12m = np.random.randint(1, 11) # 1 to 10 inclusive

    # customer_rating - value from 0.0 to 5.0
    customer_rating = round(np.random.uniform(0.0, 5.0), 1)

    # last case sentiments - value from -1 to 1 upto 1 decimal
    last_case_sentiment = round(np.random.uniform(-1.0, 1.0), 1)

    # open_disputes - number < total cases in last 12 months
    # Ensure open_disputes is non-negative and strictly less than total_cases_last_12m
    open_disputes = np.random.randint(0, total_cases_last_12m) if total_cases_last_12m > 0 else 0

    customer_ratings_records.append({
        'Cust_ID': cust_id,
        'AVG_DEBT': avg_debt,
        'prev_ptp_hit_rate': prev_ptp_hit_rate,
        'total_cases_last_12m': total_cases_last_12m,
        'customer_rating': customer_rating,
        'last_case_sentiment': last_case_sentiment,
        'open_disputes': open_disputes
    })

# Create the Customer_ratings DataFrame
Customer_ratings = pd.DataFrame(customer_ratings_records)

# Display the first few rows of the new DataFrame
display(Customer_ratings.head())

# Save to CSV for future use
Customer_ratings.to_csv('customer_ratings.csv', index=False)
print("Customer_ratings DataFrame generated and saved to 'customer_ratings.csv'")

import pandas as pd
import numpy as np
import string

# Number of DCA agents to generate
num_dca_agents = 10

# List to store records for the dca_workload DataFrame
dca_records = []

# Get industry choices from previous context, if available, otherwise define default
# Assuming industry_choices is defined in the kernel state, e.g., from new_customers_df generation
if 'industry_choices' not in globals():
    industry_choices = ['Enterprise', 'Retail', 'Healthcare', 'Manuf', 'MSME']

for i in range(num_dca_agents):
    # Generate dca_id: DCA_A, DCA_B, etc.
    # Using uppercase letters for IDs
    dca_id = f'DCA_{string.ascii_uppercase[i]}'

    # specialty: Same as used in new_customers_df (randomly pick from industry_choices)
    specialty = np.random.choice(industry_choices)

    # pending_cases: number <= 50
    pending_cases = np.random.randint(0, 51) # 0 to 50 inclusive

    # total_pending_value: random value in 1000s (e.g., 1000 * random_int)
    total_pending_value = np.random.randint(1, 101) * 1000 # Random value from 1000 to 100000 in multiples of 1000

    # max_capacity: a random number > pending cases but <100
    # Ensure max_capacity is always greater than pending_cases and less than 100
    min_capacity_bound = pending_cases + 1 # Must be greater than pending_cases
    max_capacity_bound = 100 # Must be less than 100

    if min_capacity_bound >= max_capacity_bound:
        # If pending_cases is 99 or more, max_capacity cannot be generated as per rules.
        # For simplicity, if this happens, we can cap pending_cases or ensure max_capacity is at least min_capacity_bound
        # Let's just make sure min_capacity_bound is less than 100
        if min_capacity_bound >= 100:
            max_capacity = 100 # Assign 100 if pending_cases is already too high
        else:
            max_capacity = np.random.randint(min_capacity_bound, max_capacity_bound + 1)
    else:
        max_capacity = np.random.randint(min_capacity_bound, max_capacity_bound)

    dca_records.append({
        'dca_id': dca_id,
        'specialty': specialty,
        'pending_cases': pending_cases,
        'total_pending_value': total_pending_value,
        'max_capacity': max_capacity
    })

# Create the dca_workload DataFrame
dca_workload = pd.DataFrame(dca_records)

# Display the first few rows of the new DataFrame
display(dca_workload.head())

# Save to CSV for future use
dca_workload.to_csv('dca_workload.csv', index=False)
print("dca_workload DataFrame generated and saved to 'dca_workload.csv'")

from faker import Faker
import numpy as np

fake = Faker()

num_new_customers = 100

# Generate sequential cust_id
new_cust_ids = [f'CUST_{i:03d}' for i in range(1, num_new_customers + 1)]

# Generate random customer names
new_customer_names = [fake.company() for _ in range(num_new_customers)]

# Define industry choices
industry_choices = ['Enterprise', 'Retail', 'Healthcare', 'Manuf', 'MSME']
# Generate random industries
new_industries = np.random.choice(industry_choices, size=num_new_customers).tolist()

# Generate random credit limits (e.g., between 10,000 and 500,000)
new_credit_limits = np.random.randint(10000, 500001, size=num_new_customers).tolist()

# Create the new DataFrame
new_customers_df = pd.DataFrame({
    'cust_id': new_cust_ids,
    'customer_name': new_customer_names,
    'industry': new_industries,
    'credit_limit': new_credit_limits
})

# Display the first few rows of the new DataFrame
display(new_customers_df.head())
new_customers_df.to_csv('cust_detail.csv',index = False)

from faker import Faker
import numpy as np

fake = Faker()

num_new_customers = 100

# Generate sequential cust_id
new_cust_ids = [f'CUST_{i:03d}' for i in range(1, num_new_customers + 1)]

# Generate random customer names
new_customer_names = [fake.company() for _ in range(num_new_customers)]

# Define industry choices
industry_choices = ['Enterprise', 'Retail', 'Healthcare', 'Manuf', 'MSME']
# Generate random industries
new_industries = np.random.choice(industry_choices, size=num_new_customers).tolist()

# Generate random credit limits (e.g., between 10,000 and 500,000)
new_credit_limits = np.random.randint(10000, 500001, size=num_new_customers).tolist()

# Create the new DataFrame
new_customers_df = pd.DataFrame({
    'cust_id': new_cust_ids,
    'customer_name': new_customer_names,
    'industry': new_industries,
    'credit_limit': new_credit_limits
})

# Display the first few rows of the new DataFrame
display(new_customers_df.head())
new_customers_df.to_csv('cust_detail.csv',index = False)

"""# Task
Create a DataFrame `financial_data_df` with financial records for new customers. This DataFrame will include a unique `cust_id` for each customer, multiple unique `invoice_id`s per customer, random transaction `amount`s between 1,000 and 100,000, a randomly assigned `status` of either 'paid' or 'overdue' (with a 70% chance of 'paid' and 30% chance of 'overdue'), and a `due_date`. For 'overdue' invoices, the `due_date` will be a random date up to 90 days in the past from today, and for 'paid' invoices, the `due_date` will be null. Finally, display the first few rows of the `financial_data_df` and confirm its successful creation and display for the new customer IDs.

## Generate Financial Data

### Subtask:
Create a DataFrame containing financial records for each customer. This will include generating multiple unique invoice IDs per customer, random transaction amounts, a random 'paid' or 'overdue' status for each invoice, and a past due date for any 'overdue' invoices. For 'paid' invoices, the due date will be left null.

**Reasoning**:
I need to generate financial records for each customer based on the provided instructions. This involves iterating through customers, creating invoices with random amounts and statuses, and setting due dates accordingly. I will use the `new_customers_df` DataFrame for customer IDs.
"""

import pandas as pd
import numpy as np
from datetime import datetime, timedelta

# 1. Initialize an empty list to store financial records
all_financial_records = []

# 2. Set parameters
num_invoices_per_customer_range = (1, 5)
min_amount = 1000
max_amount = 100000
paid_probability = 0.7
max_past_days = 90

# 3. Initialize invoice counter
invoice_counter = 1

# 4. Iterate through each cust_id in new_customers_df
# Assuming new_customers_df is already defined from previous steps
for cust_id in new_customers_df['cust_id']:
    # 5. Generate a random number of invoices for the current customer
    num_invoices = np.random.randint(num_invoices_per_customer_range[0], num_invoices_per_customer_range[1] + 1)

    for _ in range(num_invoices):
        # 6a. Create a unique invoice_id
        invoice_id = f'INV_{invoice_counter:05d}'
        invoice_counter += 1

        # 6b. Generate a random amount
        amount = np.random.randint(min_amount, max_amount + 1)

        # 6c. Randomly assign status
        status = 'paid' if np.random.rand() < paid_probability else 'overdue'

        due_date = None
        # 6d. If status is 'overdue', calculate a past due_date
        if status == 'overdue':
            days_past = np.random.randint(1, max_past_days + 1)
            due_date = (datetime.now() - timedelta(days=days_past)).strftime('%Y-%m-%d')

        # 6e. If status is 'paid', due_date remains None (or pd.NaT if converted to Series later)

        # 6f. Append the record to the list
        all_financial_records.append({
            'cust_id': cust_id,
            'invoice_id': invoice_id,
            'amount': amount,
            'status': status,
            'due_date': due_date
        })

# 7. Convert the list into a pandas DataFrame
financial_data_df = pd.DataFrame(all_financial_records)

# Display the first few rows of the new DataFrame
display(financial_data_df.head())

# Save to CSV for future use
financial_data_df.to_csv('financial_data.csv', index=False)
print("Financial data generated and saved to 'financial_data.csv'")

"""## Final Task

### Subtask:
Confirm the successful creation and display of the financial data for the new customer IDs.

## Summary:

### Q&A
Yes, the financial data for the new customer IDs was successfully created and displayed.

### Data Analysis Key Findings
*   A new DataFrame, `financial_data_df`, was successfully generated and displayed, containing financial records for new customer IDs.
*   The DataFrame includes columns for `cust_id`, unique `invoice_id` (e.g., 'INV\_00001'), transaction `amount`, `status`, and `due_date`.
*   Transaction `amount`s were randomly generated between 1,000 and 100,000.
*   Invoice `status` was assigned as 'paid' or 'overdue', with approximately 70% of invoices marked as 'paid' and 30% as 'overdue'.
*   For 'overdue' invoices, a `due_date` was calculated as a random date up to 90 days in the past from the current date.
*   For 'paid' invoices, the `due_date` column was correctly left as null.
*   The `financial_data_df` was also saved to a CSV file named `financial_data.csv`.

### Insights or Next Steps
*   The generated financial data is ready for further analysis, such as identifying customers with high overdue amounts or payment patterns.
*   The structured dataset can be integrated with other customer information to build a more comprehensive customer profile for targeted actions.
"""







"""THIS MARKS THE START OF CODE"""

dca_workload = pd.read_csv('dca_workload.csv')
df_customers = pd.read_csv('customer_ratings.csv')
df_customer_details = pd.read_csv('cust_detail.csv')
financial_data_df = pd.read_csv('financial_data.csv')

df_customers = pd.merge(df_customer_details, df_customers, left_on='cust_id',right_on='Cust_ID', how='left').fillna(0)

# Calculate total overdue amount for each customer
overdue_amounts = financial_data_df[financial_data_df['status'] == 'overdue'].groupby('cust_id')['amount'].sum().reset_index()
overdue_amounts.rename(columns={'amount': 'amount_overdue'}, inplace=True)

# Merge overdue amounts into df_customers, filling NaN with 0 for customers with no overdue invoices
df_customers = pd.merge(df_customers, overdue_amounts, on='cust_id', how='left').fillna({'amount_overdue': 0})

# Calculate avg_pending_value and saturation for dca_workload
dca_workload['avg_pending_value'] = dca_workload['total_pending_value'] / dca_workload['pending_cases']
dca_workload['saturation'] = dca_workload['pending_cases'] / dca_workload['max_capacity']

# Handle potential division by zero for avg_pending_value if pending_cases is 0
dca_workload['avg_pending_value'] = dca_workload['avg_pending_value'].replace([np.inf, -np.inf], 0).fillna(0)

# --- 2. CALCULATE CUSTOMER RISK INDEX (CRI) ---
def calculate_cri(row):
    # Component 1: PTP Reliability (0-30 pts)
    ptp_score = (1 - row['prev_ptp_hit_rate']) * 30

    # Component 2: Sentiment Volatility (0-20 pts)
    # Normalizing -1 to 1 into a 0 to 2 range, then multiplying
    sent_score = (1 - row['last_case_sentiment']) * 10

    # Component 3: Chronic Defaulter (Max 20 pts)
    chronic_score = min(row['total_cases_last_12m'] * 2, 20)

    # Component 4: Friction/Disputes (Max 15 pts)
    friction_score = min(row['open_disputes'] * 5, 15)

    # Component 5: Rating Inverse (0-15 pts)
    rating_score = (5 - row['customer_rating']) * 3

    return ptp_score + sent_score + chronic_score + friction_score + rating_score

df_customers['CRI'] = df_customers.apply(calculate_cri, axis=1)

# --- 3. THE ALLOCATION ENGINE (Including DCA Workload) ---

def find_best_dca(cust_row, dcas):
    best_match_score = -1
    assigned_dca = "None"

    # Filter for industry match
    eligible_dcas = dcas[dcas['specialty'] == cust_row['industry']]

    # Ensure eligible_dcas is not empty to avoid errors when iterating
    if eligible_dcas.empty:
        return pd.Series([assigned_dca, round(best_match_score, 2)])

    for _, dca in eligible_dcas.iterrows():
        # Relative Value: How much bigger is this case than their average?
        # Handle cases where avg_pending_value is zero to avoid division by zero
        if dca['avg_pending_value'] == 0:
            rel_val_index = 0 # Or some other sensible default
        else:
            rel_val_index = cust_row['amount_overdue'] / dca['avg_pending_value']

        # Match Score = Risk * Relative Value * Availability
        match_score = cust_row['CRI'] * rel_val_index * (1 - dca['saturation'])

        if match_score > best_match_score:
            best_match_score = match_score
            assigned_dca = dca['dca_id']

    return pd.Series([assigned_dca, round(best_match_score, 2)])

df_customers[['assigned_dca', 'final_priority_score']] = df_customers.apply(
    lambda row: find_best_dca(row, dca_workload), axis=1
)

print(df_customers[['cust_id', 'CRI', 'amount_overdue', 'assigned_dca', 'final_priority_score']])

from pyngrok import ngrok
import threading
import time
import subprocess

# Set your ngrok authtoken
ngrok.set_auth_token("3831kiGBJoXGWUOdmahDExFxklu_2asXa5WJYtx2VxTVWxcWS")

# Function to run Streamlit in background
def run_streamlit():
    subprocess.Popen(["streamlit", "run", "app.py", "--server.port", "8501", "--server.headless", "true"])

# Start Streamlit in a thread
threading.Thread(target=run_streamlit).start()
time.sleep(5)

# Create ngrok tunnel
public_url = ngrok.connect(8501)
print("Public URL:", public_url)
